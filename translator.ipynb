{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = pd.read_csv(\"res/pan2malay.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1, aba, aba-h\n",
    "2, abaŋ, abaŋ-an\n",
    "...\n",
    "```\n",
    "\n",
    "↓\n",
    "\n",
    "`[aba, aba-h, abaŋ, abaŋ-an...]`\n",
    "\n",
    "↓\n",
    "\n",
    "`abaaba-habaŋabaŋ-an...`\n",
    "\n",
    "↓\n",
    "\n",
    "then get all the unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_set():\n",
    "    without_index = np.delete(corpus_df.to_numpy(), 0, 1)\n",
    "    flat = without_index.flatten().astype(\"str\")\n",
    "    giant_string = \"\".join(flat)\n",
    "    return set(giant_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.], shape=(52,), dtype=float32)\n",
      "ŋ\n"
     ]
    }
   ],
   "source": [
    "encoder_mapping = list(get_char_set())\n",
    "one_hot = tf.eye(len(encoder_mapping))\n",
    "\n",
    "def encode(c):\n",
    "    return one_hot[encoder_mapping.index(c)]\n",
    "\n",
    "def decode(arr):\n",
    "    return encoder_mapping[np.argmax(arr)]\n",
    "\n",
    "vec_of_ng = encode(\"ŋ\")\n",
    "print(vec_of_ng)\n",
    "print(decode(vec_of_ng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the function for en/decoding a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     aba\n",
      "1    abaŋ\n",
      "2     adu\n",
      "3    aduq\n",
      "4    agas\n",
      "Name: pan, dtype: object\n",
      "\n",
      "encode batch of words into matrix\n",
      "(5, 64, 52, 1)\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "\n",
      "interpret the guess matrix back into word\n",
      "['aba', 'abaŋ', 'adu', 'aduq', 'agas']\n"
     ]
    }
   ],
   "source": [
    "WORD_MAX_LEN = 64\n",
    "\n",
    "def text_encoder(doc):\n",
    "    encoded = []\n",
    "    for word in doc:\n",
    "        word_matrix = tf.stack([encode(c) for c in word.ljust(WORD_MAX_LEN, \" \")])\n",
    "        encoded.append(word_matrix.numpy().reshape((WORD_MAX_LEN, len(encoder_mapping), 1)))\n",
    "    return np.stack(encoded, 0)\n",
    "\n",
    "def text_decoder(matrix_list):\n",
    "    decoded = []\n",
    "    for m in np.split(matrix_list, matrix_list.shape[0], 0):\n",
    "        reshaped = m.reshape((WORD_MAX_LEN, len(encoder_mapping)))\n",
    "        guess = \"\".join([decode(reshaped[i]) for i in range(WORD_MAX_LEN)])\n",
    "        decoded.append(str.strip(guess))\n",
    "    return decoded\n",
    "\n",
    "print(corpus_df[\"pan\"][:5])\n",
    "doc_encoding_example = text_encoder(corpus_df[\"pan\"][:5])\n",
    "print(\"\\nencode batch of words into matrix\")\n",
    "print(doc_encoding_example.shape)\n",
    "print(doc_encoding_example)\n",
    "doc_decoding_example = text_decoder(doc_encoding_example)\n",
    "print(\"\\ninterpret the guess matrix back into word\")\n",
    "print(doc_decoding_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_12 (Dropout)        (None, 64, 52, 1)         0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 64, 52, 8)         80        \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 64, 52, 8)         584       \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 64, 52, 8)         584       \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 64, 52, 1)         73        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,321\n",
      "Trainable params: 1,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(WORD_MAX_LEN, len(encoder_mapping), 1)))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Conv2D(8, (3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(keras.layers.Conv2D(8, (3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(keras.layers.Conv2D(8, (3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(keras.layers.Conv2D(1, (3,3), activation=\"sigmoid\", padding=\"same\"))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "38/38 [==============================] - 5s 98ms/step - loss: 0.5884 - accuracy: 0.9813 - val_loss: 0.3250 - val_accuracy: 0.9808\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 0.1172 - accuracy: 0.9838 - val_loss: 0.0240 - val_accuracy: 0.9977\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 3s 92ms/step - loss: 0.0188 - accuracy: 0.9965 - val_loss: 0.0120 - val_accuracy: 0.9978\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 0.0110 - val_accuracy: 0.9978\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.0106 - val_accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b623958190>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "shuffled_corpus = shuffle(corpus_df).dropna()#[:int(0.2 * corpus_df.shape[0])]\n",
    "train = shuffled_corpus[:int(0.9 * shuffled_corpus.shape[0])]\n",
    "test = shuffled_corpus[int(0.9 * shuffled_corpus.shape[0]):]\n",
    "\n",
    "model.fit(\n",
    "    text_encoder(train[\"pan\"]), \n",
    "    text_encoder(train[\"malay\"]), \n",
    "    epochs=5, batch_size=30, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raya</td>\n",
       "      <td>aaaa</td>\n",
       "      <td>raya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>akaR</td>\n",
       "      <td>aaa</td>\n",
       "      <td>akar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>su(ŋ)kab</td>\n",
       "      <td>su((ŋka</td>\n",
       "      <td>suŋkap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sendet</td>\n",
       "      <td>eeeee</td>\n",
       "      <td>tər-səndat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qatay qatay</td>\n",
       "      <td>aaaaaaaaaa</td>\n",
       "      <td>hati-hati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tunas</td>\n",
       "      <td>tuus</td>\n",
       "      <td>tunas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>taŋgiRi</td>\n",
       "      <td>aaagiii</td>\n",
       "      <td>təŋgíri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>getes</td>\n",
       "      <td>eeeee</td>\n",
       "      <td>gəntas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>sempit</td>\n",
       "      <td>ssmmi</td>\n",
       "      <td>səmpit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>bena</td>\n",
       "      <td>eee</td>\n",
       "      <td>bena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Question  Prediction CorrectAnswer\n",
       "0           Raya        aaaa          raya\n",
       "1           akaR         aaa          akar\n",
       "2       su(ŋ)kab     su((ŋka        suŋkap\n",
       "3         sendet       eeeee    tər-səndat\n",
       "4    qatay qatay  aaaaaaaaaa     hati-hati\n",
       "..           ...         ...           ...\n",
       "176        tunas        tuus         tunas\n",
       "177      taŋgiRi     aaagiii       təŋgíri\n",
       "178        getes       eeeee        gəntas\n",
       "179       sempit       ssmmi        səmpit\n",
       "180         bena         eee          bena\n",
       "\n",
       "[181 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Question\": test[\"pan\"].to_list(),\n",
    "    \"Prediction\": text_decoder(\n",
    "        model.predict(text_encoder(test[\"pan\"]))),\n",
    "    \"CorrectAnswer\": test[\"malay\"].to_list()\n",
    "}).query('Prediction != CorrectAnswer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = model.predict(text_encoder(test[\"pan\"].sample(1))).reshape(WORD_MAX_LEN, len(encoder_mapping))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(prediction[:16])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
