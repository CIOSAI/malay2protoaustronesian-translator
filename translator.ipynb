{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = pd.read_csv(\"res/pan2malay.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1, aba, aba-h\n",
    "2, abaŋ, abaŋ-an\n",
    "...\n",
    "```\n",
    "\n",
    "↓\n",
    "\n",
    "`[aba, aba-h, abaŋ, abaŋ-an...]`\n",
    "\n",
    "↓\n",
    "\n",
    "`abaaba-habaŋabaŋ-an...`\n",
    "\n",
    "↓\n",
    "\n",
    "then get all the unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_set():\n",
    "    without_index = np.delete(corpus_df.to_numpy(), 0, 1)\n",
    "    flat = without_index.flatten().astype(\"str\")\n",
    "    giant_string = \"\".join(flat)\n",
    "    return set(giant_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.], shape=(52,), dtype=float32)\n",
      "ŋ\n"
     ]
    }
   ],
   "source": [
    "encoder_mapping = list(get_char_set())\n",
    "one_hot = tf.eye(len(encoder_mapping))\n",
    "\n",
    "def encode(c):\n",
    "    return one_hot[encoder_mapping.index(c)]\n",
    "\n",
    "def decode(arr):\n",
    "    return encoder_mapping[np.argmax(arr)]\n",
    "\n",
    "vec_of_ng = encode(\"ŋ\")\n",
    "print(vec_of_ng)\n",
    "print(decode(vec_of_ng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     aba\n",
      "1    abaŋ\n",
      "2     adu\n",
      "3    aduq\n",
      "4    agas\n",
      "Name: pan, dtype: object\n",
      "\n",
      "encode batch of words into matrix\n",
      "[<tf.Tensor: shape=(128, 52), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(128, 52), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(128, 52), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(128, 52), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(128, 52), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>]\n",
      "\n",
      "interpret the guess matrix back into word\n",
      "['aba', 'abaŋ', 'adu', 'aduq', 'agas']\n"
     ]
    }
   ],
   "source": [
    "WORD_MAX_LEN = 128\n",
    "\n",
    "def text_encoder(doc):\n",
    "    encoded = []\n",
    "    for word in doc:\n",
    "        word_matrix = tf.stack([encode(c) for c in word.ljust(WORD_MAX_LEN, \" \")])\n",
    "        encoded.append(word_matrix)\n",
    "    return encoded\n",
    "\n",
    "def text_decoder(matrix_list):\n",
    "    decoded = []\n",
    "    for m in matrix_list:\n",
    "        guess = \"\".join([decode(m[i]) for i in range(WORD_MAX_LEN)])\n",
    "        decoded.append(str.strip(guess))\n",
    "    return decoded\n",
    "\n",
    "print(corpus_df[\"pan\"][:5])\n",
    "doc_encoding_example = text_encoder(corpus_df[\"pan\"][:5])\n",
    "print(\"\\nencode batch of words into matrix\")\n",
    "print(doc_encoding_example)\n",
    "doc_decoding_example = text_decoder(doc_encoding_example)\n",
    "print(\"\\ninterpret the guess matrix back into word\")\n",
    "print(doc_decoding_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 128, 32)           1696      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128, 16)           528       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128, 52)           884       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,108\n",
      "Trainable params: 3,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(WORD_MAX_LEN, len(encoder_mapping))))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(len(encoder_mapping), activation='relu'))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 52), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "shuffled_corpus = shuffle(corpus_df).dropna()\n",
    "train = shuffled_corpus[:int(0.8 * corpus_df.shape[0])]\n",
    "test = shuffled_corpus[int(0.8 * corpus_df.shape[0]):]\n",
    "\n",
    "# model.fit(\n",
    "#     text_encoder(train[\"malay\"]), \n",
    "#     text_encoder(train[\"pan\"]), \n",
    "#     epochs=4, validation_split=0.2)\n",
    "\n",
    "# model.fit(\n",
    "#     text_encoder(train[\"malay\"])[0],\n",
    "#     text_encoder(train[\"malay\"])[1]\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
